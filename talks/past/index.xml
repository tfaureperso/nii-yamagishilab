<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Past Talks | NII Yamagishi's Lab</title><link>https://zlin0.github.io/nii-yamagishilab/talks/past/</link><atom:link href="https://zlin0.github.io/nii-yamagishilab/talks/past/index.xml" rel="self" type="application/rss+xml"/><description>Past Talks</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 01 Mar 2023 11:00:00 +0900</lastBuildDate><image><url>https://zlin0.github.io/nii-yamagishilab/media/icon_hu7af45c05e7eaab656aeab8d5fe153c59_37125_512x512_fill_lanczos_center_3.png</url><title>Past Talks</title><link>https://zlin0.github.io/nii-yamagishilab/talks/past/</link></image><item><title>Enable Fact Verification across Languages via Parallel Training with Regularizations</title><link>https://zlin0.github.io/nii-yamagishilab/talks/past/2023-03-01-yc/</link><pubDate>Wed, 01 Mar 2023 11:00:00 +0900</pubDate><guid>https://zlin0.github.io/nii-yamagishilab/talks/past/2023-03-01-yc/</guid><description>&lt;h3 id="title">Title&lt;/h3>
&lt;p>Enable Fact Verification across Languages via Parallel Training with Regularizations&lt;/p>
&lt;h3 id="abstract">Abstract&lt;/h3>
&lt;p>Fact verification is part of the fact checking task. In this study, we want to enable the fact verification task across language. We will introduce a new cross-lingual fact verification dataset XFEVER, which is constructed by extending the examples of the processed FEVER dataset to 6 languages, including isolated language such as Japanese. Moreover, we apply two translation method, auto-translation and human-translation, to observe that our models&amp;rsquo; performance on different resources.
For evaluation, we will provide baselines in 2 scenarios: zero-shot transfer learning and translate-train learning. For the second scenario, we will introduce different consistency regularizations.&lt;/p>
&lt;h3 id="location-nii-1810">Location: NII 1810&lt;/h3>
&lt;h3 id="time-2023-03-01-1100--1200">Time: 2023-03-01 11:00 ~ 12:00&lt;/h3>
&lt;h3 id="other-information">Other information:&lt;/h3>
&lt;p>Please email us to get the meeting link if you are intersted!&lt;/p></description></item><item><title>Enabling Human-AI Co-Creativity in Music Making</title><link>https://zlin0.github.io/nii-yamagishilab/talks/past/2023-02-09-nicolas/</link><pubDate>Thu, 09 Feb 2023 17:00:00 +0900</pubDate><guid>https://zlin0.github.io/nii-yamagishilab/talks/past/2023-02-09-nicolas/</guid><description/></item><item><title>Few-shot Cross-speaker Style Transfer in Expressive Speech Synthesis</title><link>https://zlin0.github.io/nii-yamagishilab/talks/past/2023-02-07-gong/</link><pubDate>Tue, 07 Feb 2023 17:00:00 +0900</pubDate><guid>https://zlin0.github.io/nii-yamagishilab/talks/past/2023-02-07-gong/</guid><description/></item><item><title>Textless Phrase-Structure Induction from Visually-Grounded Speech</title><link>https://zlin0.github.io/nii-yamagishilab/talks/past/2022-12-20-jeff/</link><pubDate>Tue, 20 Dec 2022 15:00:00 +0000</pubDate><guid>https://zlin0.github.io/nii-yamagishilab/talks/past/2022-12-20-jeff/</guid><description/></item><item><title>Predicting and synthesising plausible speech examples after oral cancer treatment</title><link>https://zlin0.github.io/nii-yamagishilab/talks/past/2022-12-21-bh/</link><pubDate>Tue, 20 Dec 2022 14:00:00 +0000</pubDate><guid>https://zlin0.github.io/nii-yamagishilab/talks/past/2022-12-21-bh/</guid><description/></item></channel></rss>