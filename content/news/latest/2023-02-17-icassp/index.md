---
# Documentation: https://wowchemy.com/docs/managing-content/

title: "Four papers were accepted to ICASSP2023!"
subtitle: ""
summary: ""
authors: []
tags: [Accepted papers]
categories: []
date: 2023-02-16T23:29:53+09:00
lastmod: 2023-02-18T23:29:53+09:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []

title: Four papers were accepted to ICASSP2023!
date: 2023-02-16
image:
  focal_point: 'top'

---

We have four papers were accepted to ICASSP2023:

* Paul-Gauthier Noé, XiaoXiao Miao, Xin Wang, Junichi Yamagishi, Jean-François Bonastre, Driss Matrouf(2022). [Hiding speaker's sex in speech using zero-evidence speaker representation in an analysis/synthesis pipeline](https://zlin0.github.io/nii-yamagishilab/publication/noe-2022-hiding/)
* Xuan Shi, Erica Cooper, Xin Wang, Junichi Yamagishi, Shrikanth Narayanan (2022). [Can Knowledge of End-to-End Text-to-Speech Models Improve Neural MIDI-to-Audio Synthesis Systems?](https://zlin0.github.io/nii-yamagishilab/publication/shi-2022-can/)
* Xin Wang, Junichi Yamagishi (2022). [Spoofed training data for speech spoofing countermeasure can be efficiently created using neural vocoders](https://zlin0.github.io/nii-yamagishilab/publication/wang-2022-spoofed/)
* Haoyu Li, Yun Liu, Junichi Yamagishi (2022). [Joint Noise Reduction and Listening Enhancement for Full-End Speech Enhancement](https://zlin0.github.io/nii-yamagishilab/publication/li-2022-joint/)