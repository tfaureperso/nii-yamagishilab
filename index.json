[{"authors":null,"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1668948777,"objectID":"582b21f39122efdc484b330c43a24af0","permalink":"https://zlin0.github.io/nii-yamagishilab/author/isao-echizen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/isao-echizen/","section":"authors","summary":"","tags":null,"title":"Isao Echizen","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"0cb0a909489ffac2838902700867d77e","permalink":"https://zlin0.github.io/nii-yamagishilab/author/yamagishis-lab/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yamagishis-lab/","section":"authors","summary":"","tags":null,"title":"Yamagishi's Lab","type":"authors"},{"authors":null,"categories":null,"content":"Junichi Yamagishi received the Ph.D. degree from Tokyo Institute of Technology in 2006 for a thesis that pioneered speaker-adaptive speech synthesis. He is currently a Professor with the National Institute of Informatics, Tokyo, Japan, and also a Senior Research Fellow with the Centre for Speech Technology Research, University of Edinburgh, Edinburgh, U.K. Since 2006, he has authored and co-authored more than 250 refereed papers in international journals and conferences.\nHe was an area coordinator at Interspeech 2012. He was one of organizers for special sessions on “Spoofing and Countermeasures for Automatic Speaker Verification” at Interspeech 2013, “ASVspoof evaluation” at Interspeech 2015, “Voice conversion challenge 2016” at Interspeech 2016, “2nd ASVspoof evaluation” at Interspeech 2017, and “Voice conversion challenge 2018” at Speaker Odyssey 2018. He is currently an organizing committee for ASVspoof 2019, an organizing committee for ISCA the 10th ISCA Speech Synthesis Workshop 2019, a technical program committee for IEEE ASRU 2019, and an award committee for ISCA Speaker Odyssey 2020.\nHe was a member of IEEE Speech and Language Technical Committee. He was also an Associate Editor of the IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING and a Lead Guest Editor for the IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING special issue on Spoofing and Countermeasures for Automatic Speaker Verification. He is currently a guest editor for Computer Speech and Language special issue on speaker and language characterization and recognition: voice modeling, conversion, synthesis and ethical aspects. He also serves as a chairperson of ISCA SynSIG currently.\nHe was the recipient of the Tejima Prize as the best Ph.D. thesis of Tokyo Institute of Technology in 2007. He received the Itakura Prize from the Acoustic Society of Japan in 2010, the Kiyasu Special Industrial Achievement Award from the Information Processing Society of Japan in 2013, the Young Scientists’ Prize from the Minister of Education, Science and Technology in 2014, the JSPS Prize from Japan Society for the Promotion of Science in 2016, and Docomo mobile science award from Mobile communication fund in 2018.\n","date":1640995200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1670478233,"objectID":"fdbbe40a945160dd41e945575d9ac121","permalink":"https://zlin0.github.io/nii-yamagishilab/author/junichi-yamagishi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/junichi-yamagishi/","section":"authors","summary":"Junichi Yamagishi received the Ph.D. degree from Tokyo Institute of Technology in 2006 for a thesis that pioneered speaker-adaptive speech synthesis. He is currently a Professor with the National Institute of Informatics, Tokyo, Japan, and also a Senior Research Fellow with the Centre for Speech Technology Research, University of Edinburgh, Edinburgh, U.","tags":null,"title":"Junichi Yamagishi","type":"authors"},{"authors":null,"categories":null,"content":"Xin Wang is a Project Researcher at the National Institute of Informatics, Japan. He received the Ph.D. degree from SOKENDAI, Japan, in 2018. Before that, he received M.S. and B.E degrees from the University of Science and Technology of China and University of Electronic Science and Technology of China in 2015 and 2012, respectively. His research interests include statistical speech synthesis and machine learning.\n","date":1640995200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1670478233,"objectID":"60431f41a7738642124d36689545ee9a","permalink":"https://zlin0.github.io/nii-yamagishilab/author/xin-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/xin-wang/","section":"authors","summary":"Xin Wang is a Project Researcher at the National Institute of Informatics, Japan. He received the Ph.D. degree from SOKENDAI, Japan, in 2018. Before that, he received M.S. and B.E degrees from the University of Science and Technology of China and University of Electronic Science and Technology of China in 2015 and 2012, respectively.","tags":null,"title":"Xin Wang","type":"authors"},{"authors":null,"categories":null,"content":"Erica Cooper received a B.Sc. degree and M.Eng. degree both in electrical engineering and computer science from the Massachusetts Institute of Technology, Cambridge, MA, USA, in 2009 and 2010, respectively. She received a Ph.D. degree in computer science from Columbia University, New York, NY, USA, in 2019. Since 2019, she has been a Project Researcher with the National Institute of Informatics, Chiyoda, Tokyo, Japan. Her research interests include statistical machine learning and speech synthesis. Dr. Cooper’s awards include the 3rd Prize in the CSAW Voice Biometrics and Speech Synthesis Competition, the Computer Science Service Award from Columbia University, and the Best Poster Award in the Speech Processing Courses in Crete.\n","date":1640995200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1670478224,"objectID":"d8454c46448c7223d01580e85099c60d","permalink":"https://zlin0.github.io/nii-yamagishilab/author/erica-cooper/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/erica-cooper/","section":"authors","summary":"Erica Cooper received a B.Sc. degree and M.Eng. degree both in electrical engineering and computer science from the Massachusetts Institute of Technology, Cambridge, MA, USA, in 2009 and 2010, respectively. She received a Ph.","tags":null,"title":"Erica Cooper","type":"authors"},{"authors":null,"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1668948778,"objectID":"9b2b3c0d0409027d2a9be8ab4e57ca77","permalink":"https://zlin0.github.io/nii-yamagishilab/author/canasai-kruengkrai/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/canasai-kruengkrai/","section":"authors","summary":"","tags":null,"title":"Canasai Kruengkrai","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"5ab884c450c302340e46a95608fc966d","permalink":"https://zlin0.github.io/nii-yamagishilab/author/hieu-thi-luong/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/hieu-thi-luong/","section":"authors","summary":"","tags":null,"title":"Hieu-Thi Luong","type":"authors"},{"authors":null,"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1670478233,"objectID":"6501e27f5543f3b1589f38bee6fd8924","permalink":"https://zlin0.github.io/nii-yamagishilab/author/xiaoxiao-miao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/xiaoxiao-miao/","section":"authors","summary":"","tags":null,"title":"XiaoXiao Miao","type":"authors"},{"authors":null,"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1668948781,"objectID":"0130e056704c421a711e5bb33733d8ed","permalink":"https://zlin0.github.io/nii-yamagishilab/author/yusuke-yasuda/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yusuke-yasuda/","section":"authors","summary":"","tags":null,"title":"Yusuke Yasuda","type":"authors"},{"authors":null,"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1668948777,"objectID":"21004a495ae8232538d535debb44a64a","permalink":"https://zlin0.github.io/nii-yamagishilab/author/huy-hong-nguyen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/huy-hong-nguyen/","section":"authors","summary":"","tags":null,"title":"Huy Hong Nguyen","type":"authors"},{"authors":null,"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1668948782,"objectID":"db8c4a209c47cd6c85757c77a85fa51d","permalink":"https://zlin0.github.io/nii-yamagishilab/author/haoyu-li/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/haoyu-li/","section":"authors","summary":"","tags":null,"title":"Haoyu Li","type":"authors"},{"authors":null,"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1668948774,"objectID":"144e4dc0a52b6d1ad0ce12e165fb8b57","permalink":"https://zlin0.github.io/nii-yamagishilab/author/chang-zeng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chang-zeng/","section":"authors","summary":"","tags":null,"title":"Chang Zeng","type":"authors"},{"authors":null,"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1668948779,"objectID":"96084a286f91b5025e7ef274b43455a1","permalink":"https://zlin0.github.io/nii-yamagishilab/author/lin-zhang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/lin-zhang/","section":"authors","summary":"","tags":null,"title":"Lin Zhang","type":"authors"},{"authors":null,"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1670478224,"objectID":"84d63b784529ee3ee3a26585a3c89542","permalink":"https://zlin0.github.io/nii-yamagishilab/author/xuan-shi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/xuan-shi/","section":"authors","summary":"","tags":null,"title":"Xuan Shi","type":"authors"},{"authors":null,"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1668948768,"objectID":"1c67f3e29473721acea39fb3721b668e","permalink":"https://zlin0.github.io/nii-yamagishilab/author/yun-liu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yun-liu/","section":"authors","summary":"","tags":null,"title":"Yun Liu","type":"authors"},{"authors":null,"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1668948768,"objectID":"80b258337321422dd534e521f855e9dc","permalink":"https://zlin0.github.io/nii-yamagishilab/author/li-kuang-chen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/li-kuang-chen/","section":"authors","summary":"","tags":null,"title":"Li-Kuang Chen","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"7a5b6bb98b943e6174e5b4873c9446c7","permalink":"https://zlin0.github.io/nii-yamagishilab/author/lifan-zhong/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/lifan-zhong/","section":"authors","summary":"","tags":null,"title":"Lifan Zhong","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2eef1156111a7972e9f36f09bcf0a2a9","permalink":"https://zlin0.github.io/nii-yamagishilab/author/yi-chen-chang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yi-chen-chang/","section":"authors","summary":"","tags":null,"title":"Yi-chen Chang","type":"authors"},{"authors":null,"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1668948781,"objectID":"fd7d59cb1d33da1fbab0449a0e306bbc","permalink":"https://zlin0.github.io/nii-yamagishilab/author/yi-zhao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yi-zhao/","section":"authors","summary":"","tags":null,"title":"Yi Zhao","type":"authors"},{"authors":null,"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1668948781,"objectID":"173291836a72b51e789e45f94b86b10e","permalink":"https://zlin0.github.io/nii-yamagishilab/author/shuhei-kato/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/shuhei-kato/","section":"authors","summary":"","tags":null,"title":"Shuhei Kato","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9754051adf906143e631493ee16c7633","permalink":"https://zlin0.github.io/nii-yamagishilab/author/fuming-fang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/fuming-fang/","section":"authors","summary":"","tags":null,"title":"Fuming Fang","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"3b4973d1a2a75792bea93efac1ead917","permalink":"https://zlin0.github.io/nii-yamagishilab/author/shinji-takaki/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/shinji-takaki/","section":"authors","summary":"","tags":null,"title":"Shinji Takaki","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f5640479769e91c1c08e2aca4830274d","permalink":"https://zlin0.github.io/nii-yamagishilab/author/gustav-eje-henter/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/gustav-eje-henter/","section":"authors","summary":"","tags":null,"title":"Gustav Eje Henter","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"d639d60f1e79461bed3a8141f09a9673","permalink":"https://zlin0.github.io/nii-yamagishilab/author/jaime-lorenzo-trueba/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jaime-lorenzo-trueba/","section":"authors","summary":"","tags":null,"title":"Jaime Lorenzo-Trueba","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"5871ca992cc8cccf433ea858901854c0","permalink":"https://zlin0.github.io/nii-yamagishilab/author/fernando-villavicencio/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/fernando-villavicencio/","section":"authors","summary":"","tags":null,"title":"Fernando Villavicencio","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6119cd298c8b98a32a0dafc0f68a6f0a","permalink":"https://zlin0.github.io/nii-yamagishilab/author/kaori-takaki/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/kaori-takaki/","section":"authors","summary":"","tags":null,"title":"Kaori Takaki","type":"authors"},{"authors":[],"categories":null,"content":"Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://zlin0.github.io/nii-yamagishilab/event/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/event/example/","section":"event","summary":"An example event.","tags":[],"title":"Example Event","type":"event"},{"authors":["Bence Halpern"],"categories":[],"content":"Pathological speech synthesis has traditionally been focused on improving the error rates of downstream pathological automatic speech recognition (ASR) tasks. However, this field has the potential to have a much broader impact beyond just pathological ASR. A speech synthesis system that could predict how a patient’s voice would sound after tongue surgery or the onset of a disease, such as dysarthria, could be very useful for clinicians and patients. Such a system could be based on a surgical plan or metadata about the patient, and it could help clinicians make more informed decisions about the surgery. It could also help alleviate the stress of patients by giving them a better idea of what to expect after the surgery or onset of the disease. The talk will discuss the current progress and challenges in synthesising and evaluating pathological speech, both using voice conversion and articulatory synthesis methods.\n","date":1671494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671460193,"objectID":"dd1bbf3ed048f5c4bd5b8ac5c332e23d","permalink":"https://zlin0.github.io/nii-yamagishilab/talks/2022-12-21-bh/","publishdate":"2022-12-20T00:00:00Z","relpermalink":"/talks/2022-12-21-bh/","section":"talks","summary":"Pathological speech synthesis has traditionally been focused on improving the error rates of downstream pathological automatic speech recognition (ASR) tasks. However, this field has the potential to have a much broader impact beyond just pathological ASR.","tags":["talks"],"title":"[Dec. 21] Predicting and synthesising plausible speech examples after oral cancer treatment","type":"talks"},{"authors":["Cheng-I Jeff Lai"],"categories":[],"content":"We study phrase structure induction from visually-grounded speech without intermediate text or text pre-trained models. The core idea is to first segment the speech waveform into sequences of word segments, then induce phrase structure based on the inferred segment-level continuous representations. To this end, we present the Audio-Visual Neural Syntax Learner (AV-NSL) that learns non-trivial phrase structure by listening to audio and looking at images, without ever reading text. Experiments on SpokenCOCO, the spoken version of MSCOCO with paired images and spoken captions, show that AV-NSL infers meaningful phrase structures similar to those learned from naturally-supervised text parsing, quantitatively and qualitatively. The findings in this paper extend prior work in unsupervised language acquisition from speech and grounded grammar induction, and manifest one possibility of bridging the gap between the two fields.\n","date":1671408e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671373793,"objectID":"2943768191200434eaf59f7621c9f8e9","permalink":"https://zlin0.github.io/nii-yamagishilab/talks/2022-12-20-jeff/","publishdate":"2022-12-19T00:00:00Z","relpermalink":"/talks/2022-12-20-jeff/","section":"talks","summary":"We study phrase structure induction from visually-grounded speech without intermediate text or text pre-trained models. The core idea is to first segment the speech waveform into sequences of word segments, then induce phrase structure based on the inferred segment-level continuous representations.","tags":["talks"],"title":"[Dec. 20] Textless Phrase-Structure Induction from Visually-Grounded Speech","type":"talks"},{"authors":[],"categories":[],"content":"We are recruiting postdoctoral researchers in speech and audio processing! https://www.nii.ac.jp/en/about/recruit/2022/1007-2.html\nWe are also recruiting postdocs for topics in media processing, machine learning, multimedia security forensics, and social media! https://www.nii.ac.jp/en/about/recruit/2022/1028.html\n","date":1667260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668868193,"objectID":"15d2f8f9b062bad7fd70e63125bfe5e5","permalink":"https://zlin0.github.io/nii-yamagishilab/post/2022-11-02-recruite/","publishdate":"2022-11-01T00:00:00Z","relpermalink":"/post/2022-11-02-recruite/","section":"post","summary":"We are recruiting postdoctoral researchers in speech and audio processing! https://www.nii.ac.jp/en/about/recruit/2022/1007-2.html\nWe are also recruiting postdocs for topics in media processing, machine learning, multimedia security forensics, and social media! https://www.nii.ac.jp/en/about/recruit/2022/1028.html","tags":["Jobs"],"title":"We are recruiting postdocs!","type":"post"},{"authors":["XiaoXiao Miao","Xin Wang","Erica Cooper","Junichi Yamagishi","Natalia Tomashenko"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948770,"objectID":"441dd99c91daae0bffe33b50525a36ec","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/miao-22-interspeech/","publishdate":"2022-11-20T12:52:49.893894Z","relpermalink":"/publication/miao-22-interspeech/","section":"publication","summary":"","tags":[],"title":"Analyzing Language-Independent Speaker Anonymization Framework under Unseen Conditions","type":"publication"},{"authors":["Chang Zeng","Xin Wang","Erica Cooper","XiaoXiao Miao","Junichi Yamagishi"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948774,"objectID":"354f8d9da69032dc3264cef62616b868","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/9746688/","publishdate":"2022-11-20T12:52:54.592096Z","relpermalink":"/publication/9746688/","section":"publication","summary":"","tags":[],"title":"Attention Back-End for Automatic Speaker Verification with Multiple Enrollment Utterances","type":"publication"},{"authors":["Hemlata Tak","Massimiliano Todisco","Xin Wang","Jee-weon Jung","Junichi Yamagishi","Nicholas Evans"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948771,"objectID":"3b3d786421e94ea0595069360d168c07","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/tak-22-odyssey/","publishdate":"2022-11-20T12:52:51.691202Z","relpermalink":"/publication/tak-22-odyssey/","section":"publication","summary":"","tags":[],"title":"Automatic Speaker Verification Spoofing and Deepfake Detection Using Wav2vec 2.0 and Data Augmentation","type":"publication"},{"authors":["Xuan Shi","Erica Cooper","Xin Wang","Junichi Yamagishi","Shrikanth Narayanan"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670478224,"objectID":"6c8ed79a6b673b7cea3ad70c93b7029c","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/shi-2022-can/","publishdate":"2022-12-08T05:43:43.870261Z","relpermalink":"/publication/shi-2022-can/","section":"publication","summary":"","tags":[],"title":"Can Knowledge of End-to-End Text-to-Speech Models Improve Neural MIDI-to-Audio Synthesis Systems?","type":"publication"},{"authors":["Haoyu Li","Junichi Yamagishi"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948770,"objectID":"beae4779c04117d592cc57210bf33346","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/li-22-e-interspeech/","publishdate":"2022-11-20T12:52:50.606786Z","relpermalink":"/publication/li-22-e-interspeech/","section":"publication","summary":"","tags":[],"title":"DDS: A new device-degraded speech dataset for speech enhancement","type":"publication"},{"authors":["Xin Wang","Junichi Yamagishi"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948773,"objectID":"177ea1612e654c6e17d1bb83112b7f85","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/9746204/","publishdate":"2022-11-20T12:52:53.505524Z","relpermalink":"/publication/9746204/","section":"publication","summary":"","tags":[],"title":"Estimating the Confidence of Speech Spoofing Countermeasure","type":"publication"},{"authors":["Erica Cooper","Wen-Chin Huang","Tomoki Toda","Junichi Yamagishi"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948774,"objectID":"1ebdc0f03f8f74d3a65114df1974b974","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/9746395/","publishdate":"2022-11-20T12:52:53.861683Z","relpermalink":"/publication/9746395/","section":"publication","summary":"","tags":[],"title":"Generalization Ability of MOS Prediction Networks","type":"publication"},{"authors":["Paul-Gauthier Noé","XiaoXiao Miao","Xin Wang","Junichi Yamagishi","Jean-François Bonastre","Driss Matrouf"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670478233,"objectID":"5b9cc4c2f4fc5ba69e5bf8e6a282fb33","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/noe-2022-hiding/","publishdate":"2022-12-08T05:43:53.42705Z","relpermalink":"/publication/noe-2022-hiding/","section":"publication","summary":"","tags":[],"title":"Hiding speaker's sex in speech using zero-evidence speaker representation in an analysis/synthesis pipeline","type":"publication"},{"authors":["Xin Wang","Junich Yamagishi"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948769,"objectID":"518c8df2bfa7e4ed6774e758bb08f2ea","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/wang-2022-investigating/","publishdate":"2022-11-20T12:52:49.179822Z","relpermalink":"/publication/wang-2022-investigating/","section":"publication","summary":"","tags":[],"title":"Investigating Active-learning-based Training Data Selection for Speech Spoofing Countermeasure","type":"publication"},{"authors":["Xin Wang","Junichi Yamagishi"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948772,"objectID":"50b46476f0be9e0cfb6a1ebdf0662541","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/wang-22-odyssey/","publishdate":"2022-11-20T12:52:52.053779Z","relpermalink":"/publication/wang-22-odyssey/","section":"publication","summary":"","tags":[],"title":"Investigating Self-Supervised Front Ends for Speech Spoofing Countermeasures","type":"publication"},{"authors":["Haoyu Li","Yun Liu","Junichi Yamagishi"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948768,"objectID":"a710855db33808e13e8bb2dd2035a213","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/li-2022-joint/","publishdate":"2022-11-20T12:52:48.455585Z","relpermalink":"/publication/li-2022-joint/","section":"publication","summary":"","tags":[],"title":"Joint Noise Reduction and Listening Enhancement for Full-End Speech Enhancement","type":"publication"},{"authors":["Chang Zeng","XiaoXiao Miao","Xin Wang","Erica Cooper","Junichi Yamagishi"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948767,"objectID":"64c5fff771c898b49397b191ec07d06f","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/zeng-2022-joint/","publishdate":"2022-11-20T12:52:47.732097Z","relpermalink":"/publication/zeng-2022-joint/","section":"publication","summary":"","tags":[],"title":"Joint Speaker Encoder and Neural Back-end Model for Fully End-to-End Automatic Speaker Verification with Multiple Enrollment Utterances","type":"publication"},{"authors":["XiaoXiao Miao","Xin Wang","Erica Cooper","Junichi Yamagishi","Natalia Tomashenko"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948771,"objectID":"8c763f2edbbaa7e5b7cb4904a8a33306","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/miao-22-odyssey/","publishdate":"2022-11-20T12:52:51.333192Z","relpermalink":"/publication/miao-22-odyssey/","section":"publication","summary":"","tags":[],"title":"Language-Independent Speaker Anonymization Approach Using Self-Supervised Pre-Trained Models","type":"publication"},{"authors":["Huy Hong Nguyen","Sebastien Marcel","Junichi Yamagishi","Isao Echizen"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948772,"objectID":"46f16ee7e66333c8beff3675329865bb","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/9758063/","publishdate":"2022-11-20T12:52:52.419931Z","relpermalink":"/publication/9758063/","section":"publication","summary":"","tags":[],"title":"Master Face Attacks on Face Recognition Systems","type":"publication"},{"authors":["Canasai Kruengkrai","Junichi Yamagishi"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948769,"objectID":"15e2246ea850b21ac2205876615a6be9","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/kruengkrai-2022-mitigating/","publishdate":"2022-11-20T12:52:49.537811Z","relpermalink":"/publication/kruengkrai-2022-mitigating/","section":"publication","summary":"","tags":[],"title":"Mitigating the Diminishing Effect of Elastic Weight Consolidation","type":"publication"},{"authors":["Cheng-I Jeff Lai","Erica Cooper","Yang Zhang","Shiyu Chang","Kaizhi Qian","Yi-Lun Liao","Yung-Sung Chuang","Alexander H. Liu","Junichi Yamagishi","David Cox","James Glass"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948774,"objectID":"7295f017114e5d625f442c55ee15b7b9","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/9747728/","publishdate":"2022-11-20T12:52:54.224937Z","relpermalink":"/publication/9747728/","section":"publication","summary":"","tags":[],"title":"On the Interplay between Sparsity, Naturalness, Intelligibility, and Prosody in Speech Synthesis","type":"publication"},{"authors":["Anssi Kanervisto","Ville Hautam\u0026#x00E4;ki","Tomi Kinnunen","Junichi Yamagishi"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948775,"objectID":"bf014dd606165f8766a5fdd17d5be300","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/9664367/","publishdate":"2022-11-20T12:52:55.316613Z","relpermalink":"/publication/9664367/","section":"publication","summary":"","tags":[],"title":"Optimizing Tandem Speaker Verification and Anti-Spoofing Systems","type":"publication"},{"authors":["Li-Kuang Chen","Canasai Kruengkrai","Junichi Yamagishi"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948768,"objectID":"88e6b553c2d10a87c396b2cdc31d2429","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/chen-2022-outlier/","publishdate":"2022-11-20T12:52:48.828241Z","relpermalink":"/publication/chen-2022-outlier/","section":"publication","summary":"","tags":[],"title":"Outlier-Aware Training for Improving Group Accuracy Disparities","type":"publication"},{"authors":["Xin Wang","Junichi Yamagishi"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948767,"objectID":"516a858002d9b06c8efa3e0e3abdba88","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/wang-2022-spoofed/","publishdate":"2022-11-20T12:52:47.375417Z","relpermalink":"/publication/wang-2022-spoofed/","section":"publication","summary":"","tags":[],"title":"Spoofed training data for speech spoofing countermeasure can be efficiently created using neural vocoders","type":"publication"},{"authors":["Chang Zeng","Lin Zhang","Meng Liu","Junichi Yamagishi"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948771,"objectID":"c2abb11e75f31b801a12e45f71af679c","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/zeng-22-interspeech/","publishdate":"2022-11-20T12:52:50.974254Z","relpermalink":"/publication/zeng-22-interspeech/","section":"publication","summary":"","tags":[],"title":"Spoofing-Aware Attention based ASV Back-end with Multiple Enrollment Utterances and a Sampling Strategy for the SASV Challenge 2022","type":"publication"},{"authors":["Cheng-Hung Hu","Yu-Huai Peng","Junichi Yamagishi","Yu Tsao","Hsin-Min Wang"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948773,"objectID":"c4975ab4c747daf1794a45355e2e3896","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/9716822/","publishdate":"2022-11-20T12:52:53.140244Z","relpermalink":"/publication/9716822/","section":"publication","summary":"","tags":[],"title":"SVSNet: An End-to-End Speaker Voice Similarity Assessment Model","type":"publication"},{"authors":["Lin Zhang","Xin Wang","Erica Cooper","Nicholas Evans","Junichi Yamagishi"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948768,"objectID":"b2ea465bf926fe52172d6ad9afcc5ed2","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/zhang-2022-partialspoof/","publishdate":"2022-11-20T12:52:48.098004Z","relpermalink":"/publication/zhang-2022-partialspoof/","section":"publication","summary":"","tags":[],"title":"The PartialSpoof Database and Countermeasures for the Detection of Short Generated Audio Segments Embedded in a Speech Utterance","type":"publication"},{"authors":["Wen Chin Huang","Erica Cooper","Yu Tsao","Hsin-Min Wang","Tomoki Toda","Junichi Yamagishi"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948770,"objectID":"1d23b0baaea39fe2d4caae480e4759a7","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/huang-22-f-interspeech/","publishdate":"2022-11-20T12:52:50.247958Z","relpermalink":"/publication/huang-22-f-interspeech/","section":"publication","summary":"","tags":[],"title":"The VoiceMOS Challenge 2022","type":"publication"},{"authors":["Natalia Tomashenko","Xin Wang","Emmanuel Vincent","Jose Patino","Brij Mohan Lal Srivastava","Paul-Gauthier Noé","Andreas Nautsch","Nicholas Evans","Junichi Yamagishi","Benjamin O’Brien"," others"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948772,"objectID":"ae0ffaa99ed85114c9150e8a4eeb8f73","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/tomashenko-2022-voiceprivacy/","publishdate":"2022-11-20T12:52:52.781113Z","relpermalink":"/publication/tomashenko-2022-voiceprivacy/","section":"publication","summary":"","tags":[],"title":"The VoicePrivacy 2020 Challenge: Results and findings","type":"publication"},{"authors":["Xuan Shi","Erica Cooper","Junichi Yamagishi"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948775,"objectID":"3a1ed5bb960fad110b669c462f144b2d","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/9670718/","publishdate":"2022-11-20T12:52:54.954009Z","relpermalink":"/publication/9670718/","section":"publication","summary":"","tags":[],"title":"Use of Speaker Recognition Approaches for Learning and Evaluating Embedding Representations of Musical Instrument Sounds","type":"publication"},{"authors":["Xin Wang","Junichi Yamagishi"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948780,"objectID":"abedc1cffc85ec35634762e884c13fb0","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/wang-21-fa-interspeech/","publishdate":"2022-11-20T12:53:00.063444Z","relpermalink":"/publication/wang-21-fa-interspeech/","section":"publication","summary":"","tags":[],"title":"A Comparative Study on Recent Neural Spoofing Countermeasures for Synthetic Speech Detection","type":"publication"},{"authors":["Canasai Kruengkrai","Junichi Yamagishi","Xin Wang"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948778,"objectID":"6f26f7f7c65029c8b3b266a3b1d59285","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/kruengkrai-2021-multi/","publishdate":"2022-11-20T12:52:57.849099Z","relpermalink":"/publication/kruengkrai-2021-multi/","section":"publication","summary":"","tags":[],"title":"A multi-level attention model for evidence-based fact checking","type":"publication"},{"authors":["Lin Zhang","Xin Wang","Erica Cooper","Junichi Yamagishi","Jose Patino","Nicholas Evans"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948779,"objectID":"175023e5f44464b986229456822d9068","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/zhang-21-ca-interspeech/","publishdate":"2022-11-20T12:52:59.705422Z","relpermalink":"/publication/zhang-21-ca-interspeech/","section":"publication","summary":"","tags":[],"title":"An Initial Investigation for Detecting Partially Spoofed Audio","type":"publication"},{"authors":["Andreas Nautsch","Xin Wang","Nicholas Evans","Tomi H. Kinnunen","Ville Vestman","Massimiliano Todisco","Héctor Delgado","Md Sahidullah","Junichi Yamagishi","Kong Aik Lee"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948780,"objectID":"7f92130a8a5d03443818de88584d88a6","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/9358099/","publishdate":"2022-11-20T12:53:00.422305Z","relpermalink":"/publication/9358099/","section":"publication","summary":"","tags":[],"title":"ASVspoof 2019: Spoofing Countermeasures for the Detection of Synthesized, Converted and Replayed Speech","type":"publication"},{"authors":["Junichi Yamagishi","Xin Wang","Massimiliano Todisco","Md Sahidullah","Jose Patino","Andreas Nautsch","Xuechen Liu","Kong Aik Lee","Tomi Kinnunen","Nicholas Evans","Héctor Delgado"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948776,"objectID":"fe6ec06fd947498be001c16a2d0eed95","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/yamagishi-21-asvspoof/","publishdate":"2022-11-20T12:52:56.74999Z","relpermalink":"/publication/yamagishi-21-asvspoof/","section":"publication","summary":"","tags":[],"title":"ASVspoof 2021: accelerating progress in spoofed and deepfake speech detection","type":"publication"},{"authors":["Jean-François Bonastre","Héctor Delgado","Nicholas Evans","Tomi Kinnunen","Kong Aik Lee","Xuechen Liu","Andreas Nautsch","‪Paul-Gauthier Noé‬","Jose Patino","Md Sahidullah","Brij Mohan Lal Srivastava","Massimiliano Todisco","Natalia Tomashenko","Emmanuel Vincent","Xin Wang","Junichi Yamagishi"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948776,"objectID":"8dae7009871cbc08b32c3995f0be31ac","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/bonastre-21-spsc/","publishdate":"2022-11-20T12:52:56.394681Z","relpermalink":"/publication/bonastre-21-spsc/","section":"publication","summary":"","tags":[],"title":"Benchmarking and challenges in security and privacy for voice biometrics","type":"publication"},{"authors":["Yang Ai","Haoyu Li","Xin Wang","Junichi Yamagishi","Zhenhua Ling"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948782,"objectID":"aae19708afae62042317c2a9a17ffe57","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/9383611/","publishdate":"2022-11-20T12:53:02.18928Z","relpermalink":"/publication/9383611/","section":"publication","summary":"","tags":[],"title":"Denoising-and-Dereverberation Hierarchical Neural Vocoder for Robust Waveform Generation","type":"publication"},{"authors":["Khanh-Duv Nguyen","Huv H. Nguyen","Trung-Nghia Le","Junichi Yamagishi","Isao Echizen"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948775,"objectID":"293b9f336c0dc6930aa7f312b120c13e","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/9667046/","publishdate":"2022-11-20T12:52:55.677145Z","relpermalink":"/publication/9667046/","section":"publication","summary":"","tags":[],"title":"Effectiveness of Detection-based and Regression-based Approaches for Estimating Mask-Wearing Ratio","type":"publication"},{"authors":["Yusuke Yasuda","Xin Wang","Junichi Yamagishd"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948780,"objectID":"38a37dc519e6869ab582178d85101be3","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/9414499/","publishdate":"2022-11-20T12:53:00.774243Z","relpermalink":"/publication/9414499/","section":"publication","summary":"","tags":[],"title":"End-to-End Text-to-Speech Using Latent Duration Based on VQ-VAE","type":"publication"},{"authors":["Haoyu Li","Yang Ai","Junichi Yamagishi"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948781,"objectID":"dda2c7f52bdeb3eeb992686c4e421baf","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/9383507/","publishdate":"2022-11-20T12:53:01.828429Z","relpermalink":"/publication/9383507/","section":"publication","summary":"","tags":[],"title":"Enhancing Low-Quality Voice Recordings Using Disentangled Channel Factor and Neural Waveform Model","type":"publication"},{"authors":["Jennifer Williams","Jason Fong","Erica Cooper","Junichi Yamagishi"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948779,"objectID":"ad4e82ca1695e8d20b19a8cee7afb34d","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/williams-21-ssw/","publishdate":"2022-11-20T12:52:58.993419Z","relpermalink":"/publication/williams-21-ssw/","section":"publication","summary":"","tags":[],"title":"Exploring Disentanglement with Multilingual and Monolingual VQ-VAE","type":"publication"},{"authors":["Erica Cooper","Junichi Yamagishi"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948778,"objectID":"4bf59de148f6e8f1de7b786f5c35a71d","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/cooper-21-ssw/","publishdate":"2022-11-20T12:52:58.239502Z","relpermalink":"/publication/cooper-21-ssw/","section":"publication","summary":"","tags":[],"title":"How do Voices from Past Speech Synthesis Challenges Compare Today?","type":"publication"},{"authors":["Shuhei Kato","Yusuke Yasuda","Xin Wang","Erica Cooper","Junichi Yamagishi"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948781,"objectID":"07cb39b0b425f9ae534894532701a5c1","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/9414175/","publishdate":"2022-11-20T12:53:01.479497Z","relpermalink":"/publication/9414175/","section":"publication","summary":"","tags":[],"title":"How Similar or Different is Rakugo Speech Synthesizer to Professional Performers?","type":"publication"},{"authors":["Jennifer Williams","Yi Zhao","Erica Cooper","Junichi Yamagishi"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948781,"objectID":"132c6fa04ad2902f260559cffdf5aa37","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/9413543/","publishdate":"2022-11-20T12:53:01.127144Z","relpermalink":"/publication/9413543/","section":"publication","summary":"","tags":[],"title":"Learning Disentangled Phone and Speaker Representations in a Semi-Supervised VQ-VAE Paradigm","type":"publication"},{"authors":["Haoyu Li","Junichi Yamagishi"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948779,"objectID":"9d8e2cc9aa609322cb53c8ff30e76712","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/9536406/","publishdate":"2022-11-20T12:52:59.344943Z","relpermalink":"/publication/9536406/","section":"publication","summary":"","tags":[],"title":"Multi-Metric Optimization Using Generative Adversarial Networks for Near-End Speech Intelligibility Enhancement","type":"publication"},{"authors":["Lin Zhang","Xin Wang","Erica Cooper","Junichi Yamagishi"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948777,"objectID":"2b7b0e69c16c3cac45f66a75ebaf3a87","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/zhang-21-asvspoof/","publishdate":"2022-11-20T12:52:57.133123Z","relpermalink":"/publication/zhang-21-asvspoof/","section":"publication","summary":"","tags":[],"title":"Multi-task Learning in Utterance-level and Segmental-level Spoof Detection","type":"publication"},{"authors":["Trung-Nghia Le","Huy Hong Nguyen","Junichi Yamagishi","Isao Echizen"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948777,"objectID":"47c4866217f2b53eadb8bedc872e69e3","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/9711250/","publishdate":"2022-11-20T12:52:57.484095Z","relpermalink":"/publication/9711250/","section":"publication","summary":"","tags":[],"title":"OpenForensics: Large-Scale Challenging Dataset For Multi-Face Forgery Detection And Segmentation In-The-Wild","type":"publication"},{"authors":["Jennifer Williams","Junichi Yamagishi"," Paul-Gauthier","Cassia Valentini-Botinhao","Jean-François Bonastre"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948776,"objectID":"9f279964c7f0ca1d3ebed8744367dbbb","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/williams-21-spsc/","publishdate":"2022-11-20T12:52:56.035461Z","relpermalink":"/publication/williams-21-spsc/","section":"publication","summary":"","tags":[],"title":"Revisiting Speech Content Privacy","type":"publication"},{"authors":["Erica Cooper","Xin Wang","Junichi Yamagishi"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668948778,"objectID":"cd994f411d0b54551c083cd41004dcad","permalink":"https://zlin0.github.io/nii-yamagishilab/publication/cooper-21-b-ssw/","publishdate":"2022-11-20T12:52:58.633825Z","relpermalink":"/publication/cooper-21-b-ssw/","section":"publication","summary":"","tags":[],"title":"Text-to-Speech Synthesis Techniques for MIDI-to-Audio Synthesis","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://zlin0.github.io/nii-yamagishilab/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7573a1c1fd05033a6452bb7f481d53bf","permalink":"https://zlin0.github.io/nii-yamagishilab/materials/challenges/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/materials/challenges/","section":"materials","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9a1c33b5f9ea4797034df9a0a649a66c","permalink":"https://zlin0.github.io/nii-yamagishilab/materials/downloads/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/materials/downloads/","section":"materials","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://zlin0.github.io/nii-yamagishilab/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b0d61e5cbb7472bf320bf0ef2aaeb977","permalink":"https://zlin0.github.io/nii-yamagishilab/tour/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/tour/","section":"","summary":"","tags":null,"title":"Tour","type":"widget_page"}]