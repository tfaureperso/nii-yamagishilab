<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Accepted papers | NII Yamagishi's Lab</title><link>https://zlin0.github.io/nii-yamagishilab/tag/accepted-papers/</link><atom:link href="https://zlin0.github.io/nii-yamagishilab/tag/accepted-papers/index.xml" rel="self" type="application/rss+xml"/><description>Accepted papers</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 16 Feb 2023 00:00:00 +0000</lastBuildDate><image><url>https://zlin0.github.io/nii-yamagishilab/media/icon_hu7af45c05e7eaab656aeab8d5fe153c59_37125_512x512_fill_lanczos_center_3.png</url><title>Accepted papers</title><link>https://zlin0.github.io/nii-yamagishilab/tag/accepted-papers/</link></image><item><title>Four papers were accepted to ICASSP2023!</title><link>https://zlin0.github.io/nii-yamagishilab/news/latest/2023-02-17-icassp/</link><pubDate>Thu, 16 Feb 2023 00:00:00 +0000</pubDate><guid>https://zlin0.github.io/nii-yamagishilab/news/latest/2023-02-17-icassp/</guid><description>&lt;p>We have four papers were accepted to ICASSP2023:&lt;/p>
&lt;ul>
&lt;li>Paul-Gauthier Noé, XiaoXiao Miao, Xin Wang, Junichi Yamagishi, Jean-François Bonastre, Driss Matrouf(2022). &lt;a href="https://zlin0.github.io/nii-yamagishilab/publication/noe-2022-hiding/" target="_blank" rel="noopener">Hiding speaker&amp;rsquo;s sex in speech using zero-evidence speaker representation in an analysis/synthesis pipeline&lt;/a>&lt;/li>
&lt;li>Xuan Shi, Erica Cooper, Xin Wang, Junichi Yamagishi, Shrikanth Narayanan (2022). &lt;a href="https://zlin0.github.io/nii-yamagishilab/publication/shi-2022-can/" target="_blank" rel="noopener">Can Knowledge of End-to-End Text-to-Speech Models Improve Neural MIDI-to-Audio Synthesis Systems?&lt;/a>&lt;/li>
&lt;li>Xin Wang, Junichi Yamagishi (2022). &lt;a href="https://zlin0.github.io/nii-yamagishilab/publication/wang-2022-spoofed/" target="_blank" rel="noopener">Spoofed training data for speech spoofing countermeasure can be efficiently created using neural vocoders&lt;/a>&lt;/li>
&lt;li>Haoyu Li, Yun Liu, Junichi Yamagishi (2022). &lt;a href="https://zlin0.github.io/nii-yamagishilab/publication/li-2022-joint/" target="_blank" rel="noopener">Joint Noise Reduction and Listening Enhancement for Full-End Speech Enhancement&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>