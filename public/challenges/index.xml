<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Challenges | NII Yamagishi&#39;s Lab</title>
    <link>https://zlin0.github.io/nii-yamagishilab/challenges/</link>
      <atom:link href="https://zlin0.github.io/nii-yamagishilab/challenges/index.xml" rel="self" type="application/rss+xml" />
    <description>Challenges</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 01 Jan 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://zlin0.github.io/nii-yamagishilab/media/icon_hu7af45c05e7eaab656aeab8d5fe153c59_37125_512x512_fill_lanczos_center_3.png</url>
      <title>Challenges</title>
      <link>https://zlin0.github.io/nii-yamagishilab/challenges/</link>
    </image>
    
    <item>
      <title>ASVspoof</title>
      <link>https://zlin0.github.io/nii-yamagishilab/challenges/asvspoof/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://zlin0.github.io/nii-yamagishilab/challenges/asvspoof/</guid>
      <description>&lt;h1 id=&#34;asvspoofhttpswwwasvspooforg&#34;&gt;&lt;a href=&#34;https://www.asvspoof.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ASVspoof&lt;/a&gt;&lt;/h1&gt;
&lt;h2 id=&#34;latest-information&#34;&gt;Latest Information&lt;/h2&gt;
&lt;p&gt;Upcoming ASVspoof5 in 2023:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Database creation:          Autumn, 2022&lt;/li&gt;
&lt;li&gt;Challenge set-up:            First half, 2023&lt;/li&gt;
&lt;li&gt;ASVspoof5 challenge:     Second half, 2023&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- 

## Introduction


## Organisers
(in alphabetical order) --&gt;
</description>
    </item>
    
    <item>
      <title>VoiceMOS</title>
      <link>https://zlin0.github.io/nii-yamagishilab/challenges/voicemos/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://zlin0.github.io/nii-yamagishilab/challenges/voicemos/</guid>
      <description>&lt;h1 id=&#34;voicemoshttpsvoicemos-challenge-2022githubio&#34;&gt;&lt;a href=&#34;https://voicemos-challenge-2022.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VoiceMOS&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;The VoiceMOS Challenge 2022 has ended! Material from the challenge will remain available online. Read our summary paper of the challenge &lt;a href=&#34;https://arxiv.org/abs/2203.11389&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Human listening tests are the gold standard for evaluating synthesized speech. Objective measures of speech quality have low correlation with human ratings, and the generalization abilities of current data-driven quality prediction systems suffer significantly from domain mismatch. The VoiceMOS Challenge aims to encourage research in the area of automatic prediction of Mean Opinion Scores (MOS) for synthesized speech.&lt;/p&gt;
&lt;h2 id=&#34;organisers&#34;&gt;Organisers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Wen-Chin Huang (Nagoya University, Japan)&lt;/li&gt;
&lt;li&gt;Erica Cooper (National Institute of Informatics, Japan)&lt;/li&gt;
&lt;li&gt;Yu Tsao (Academia Sinica, Taiwan)&lt;/li&gt;
&lt;li&gt;Hsin-Min Wang (Academia Sinica, Taiwan)&lt;/li&gt;
&lt;li&gt;Tomoki Toda (Nagoya University, Japan)&lt;/li&gt;
&lt;li&gt;Junichi Yamagishi (National Institute of Informatics, Japan)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>VoicePrivacy</title>
      <link>https://zlin0.github.io/nii-yamagishilab/challenges/voiceprivacy/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://zlin0.github.io/nii-yamagishilab/challenges/voiceprivacy/</guid>
      <description>&lt;h1 id=&#34;voiceprivacyhttpswwwvoiceprivacychallengeorg&#34;&gt;&lt;a href=&#34;https://www.voiceprivacychallenge.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VoicePrivacy&lt;/a&gt;&lt;/h1&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Formed in 2020, the VoicePrivacy initiative is spearheading the effort to develop privacy preservations solutions for speech technology. We aim to foster progress in the development of anonymisation and pseudonymisation solutions which suppress personally identifiable information contained within recordings of speech while preserving linguistic content and speech quality/naturalness. VoicePrivacy takes the form of a competitive benchmarking challenge, with common datasets, protocols and metrics. The first edition of VoicePrivacy was held in 2020, culminating in a special sessions held at INTERSPEECH 2020 and Odyssey 2020, and a special issue published in Elsevier Computer Speech and Language. VoicePrivacy 2022 is the second edition starts from March 2022.&lt;/p&gt;
&lt;h2 id=&#34;organisers&#34;&gt;Organisers&lt;/h2&gt;
&lt;p&gt;(in alphabetical order)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Jean-Fran√ßois Bonastre - University of Avignon - LIA, France&lt;/li&gt;
&lt;li&gt;Pierre Champion - Inria, France&lt;/li&gt;
&lt;li&gt;Nicholas Evans - EURECOM, France&lt;/li&gt;
&lt;li&gt;Xiaoxiao Miao - NII, Japan&lt;/li&gt;
&lt;li&gt;Hubert Nourtel - Inria, France&lt;/li&gt;
&lt;li&gt;Massimiliano Todisco - EURECOM, France&lt;/li&gt;
&lt;li&gt;Natalia Tomashenko - University of Avignon - LIA, France&lt;/li&gt;
&lt;li&gt;Emmanuel Vincent - Inria, France&lt;/li&gt;
&lt;li&gt;Xin Wang - NII, Japan&lt;/li&gt;
&lt;li&gt;Junichi Yamagishi - NII, Japan and University of Edinburgh, UK&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
