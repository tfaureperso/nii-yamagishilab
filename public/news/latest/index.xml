<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Latest News | NII Yamagishi&#39;s Lab</title>
    <link>https://zlin0.github.io/nii-yamagishilab/news/latest/</link>
      <atom:link href="https://zlin0.github.io/nii-yamagishilab/news/latest/index.xml" rel="self" type="application/rss+xml" />
    <description>Latest News</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 16 Feb 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://zlin0.github.io/nii-yamagishilab/media/icon_hu7af45c05e7eaab656aeab8d5fe153c59_37125_512x512_fill_lanczos_center_3.png</url>
      <title>Latest News</title>
      <link>https://zlin0.github.io/nii-yamagishilab/news/latest/</link>
    </image>
    
    <item>
      <title>Four papers were accepted to ICASSP2023!</title>
      <link>https://zlin0.github.io/nii-yamagishilab/news/latest/2023-02-17-icassp/</link>
      <pubDate>Thu, 16 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://zlin0.github.io/nii-yamagishilab/news/latest/2023-02-17-icassp/</guid>
      <description>&lt;p&gt;We have four papers were accepted to ICASSP2023:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Paul-Gauthier Noé, XiaoXiao Miao, Xin Wang, Junichi Yamagishi, Jean-François Bonastre, Driss Matrouf(2022). &lt;a href=&#34;https://zlin0.github.io/nii-yamagishilab/publication/noe-2022-hiding/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hiding speaker&amp;rsquo;s sex in speech using zero-evidence speaker representation in an analysis/synthesis pipeline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Xuan Shi, Erica Cooper, Xin Wang, Junichi Yamagishi, Shrikanth Narayanan (2022). &lt;a href=&#34;https://zlin0.github.io/nii-yamagishilab/publication/shi-2022-can/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Can Knowledge of End-to-End Text-to-Speech Models Improve Neural MIDI-to-Audio Synthesis Systems?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Xin Wang, Junichi Yamagishi (2022). &lt;a href=&#34;https://zlin0.github.io/nii-yamagishilab/publication/wang-2022-spoofed/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Spoofed training data for speech spoofing countermeasure can be efficiently created using neural vocoders&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Haoyu Li, Yun Liu, Junichi Yamagishi (2022). &lt;a href=&#34;https://zlin0.github.io/nii-yamagishilab/publication/li-2022-joint/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Joint Noise Reduction and Listening Enhancement for Full-End Speech Enhancement&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
