<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=stylesheet href=/nii-yamagishilab/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css integrity crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/nii-yamagishilab/css/wowchemy.f3c28803eb07089619aac681dc14ff29.css><link rel=stylesheet href=/nii-yamagishilab/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/nii-yamagishilab/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Junichi Yamagishi"><meta name=description content="Professor"><link rel=alternate hreflang=en-us href=https://zlin0.github.io/nii-yamagishilab/author/xin-wang/><link rel=canonical href=https://zlin0.github.io/nii-yamagishilab/author/xin-wang/><link rel=manifest href=/nii-yamagishilab/manifest.webmanifest><link rel=icon type=image/png href=/nii-yamagishilab/media/icon_hu7af45c05e7eaab656aeab8d5fe153c59_37125_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/nii-yamagishilab/media/icon_hu7af45c05e7eaab656aeab8d5fe153c59_37125_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#3f51b5"><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@yamagishilab"><meta property="twitter:creator" content="@yamagishilab"><meta property="twitter:image" content="https://zlin0.github.io/nii-yamagishilab/author/xin-wang/avatar_hu62fc513cb77284af5ce87c8c3b5d15b8_147648_270x270_fill_q75_lanczos_center.jpg"><meta property="og:site_name" content="NII Yamagishi's Lab"><meta property="og:url" content="https://zlin0.github.io/nii-yamagishilab/author/xin-wang/"><meta property="og:title" content="Xin Wang | NII Yamagishi's Lab"><meta property="og:description" content="Professor"><meta property="og:image" content="https://zlin0.github.io/nii-yamagishilab/author/xin-wang/avatar_hu62fc513cb77284af5ce87c8c3b5d15b8_147648_270x270_fill_q75_lanczos_center.jpg"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2023-02-18T00:00:00+00:00"><link rel=alternate href=/nii-yamagishilab/author/xin-wang/index.xml type=application/rss+xml title="NII Yamagishi's Lab"><title>Xin Wang | NII Yamagishi's Lab</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=60431f41a7738642124d36689545ee9a><script src=/nii-yamagishilab/js/wowchemy-init.min.fe8634e7d00f14d07fb33caf14cc8e55.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>NII Yamagishi's Lab</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>NII Yamagishi's Lab</a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>News</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/nii-yamagishilab/news/latest/><span>Latest</span></a>
<a class=dropdown-item href=/nii-yamagishilab/news/old/><span>Old</span></a></div></li><li class=nav-item><a class=nav-link href=/nii-yamagishilab/people><span>Members</span></a></li><li class=nav-item><a class=nav-link href=/nii-yamagishilab/publication><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/nii-yamagishilab/challenges><span>Challenges</span></a></li><li class=nav-item><a class=nav-link href=/nii-yamagishilab/databases><span>Databases</span></a></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Talks</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/nii-yamagishilab/talks/upcoming/><span>Upcoming</span></a>
<a class=dropdown-item href=/nii-yamagishilab/talks/past/><span>Past</span></a></div></li><li class=nav-item><a class=nav-link href=/nii-yamagishilab/grants><span>Grants</span></a></li><li class=nav-item><a class=nav-link href=/nii-yamagishilab/recruitments><span>Recruitments</span></a></li><li class=nav-item><a class=nav-link href=/nii-yamagishilab/contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li></ul></div></nav></header></div><div class=page-body><section id=profile-page class=pt-5><div class=container><div class=row><div class="col-12 col-lg-4"><div id=profile><img class="avatar avatar-circle" width=270 height=270 src=/nii-yamagishilab/author/xin-wang/avatar_hu62fc513cb77284af5ce87c8c3b5d15b8_147648_270x270_fill_q75_lanczos_center.jpg alt="Xin Wang"><div class=portrait-title><h2>Xin Wang</h2><h3>Project Assistant Professor</h3><h3><span>National Institute of Informatics</span></h3></div><ul class=network-icon aria-hidden=true><li><a href=https://tonywangx.github.io/ target=_blank rel=noopener aria-label=house><i class="fas fa-house big-icon"></i></a></li><li><a href=https://researchmap.jp/wangxin target=_blank rel=noopener aria-label=external-link-alt><i class="fas fa-external-link-alt big-icon"></i></a></li><li><a href="https://scholar.google.com/citations?user=uMZhUHcAAAAJ&amp;hl=en" target=_blank rel=noopener aria-label=google-scholar><i class="ai ai-google-scholar big-icon"></i></a></li><li><a href=https://github.com/TonyWangX target=_blank rel=noopener aria-label=github><i class="fab fa-github big-icon"></i></a></li></ul></div></div><div class="col-12 col-lg-8"><div class=article-style><p>Xin Wang is a Project Researcher at the National Institute of Informatics, Japan. He received the Ph.D. degree from SOKENDAI, Japan, in 2018. Before that, he received M.S. and B.E degrees from the University of Science and Technology of China and University of Electronic Science and Technology of China in 2015 and 2012, respectively. His research interests include statistical speech synthesis and machine learning.</p></div><div class=row><div class=col-md-7><div class=section-subheading>Education</div><ul class="ul-edu fa-ul mb-0"><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>PhD, 2018</p><p class=institution>National Institute of Informatics, SOKENDAI, Tokyo, Japan.</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>MSc, 2015</p><p class=institution>University of Science and Technology of China, Hefei, China.</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>BSc, 2012</p><p class=institution>University of Electronic Science and Technology of China, Chengdu, China.</p></div></li></ul></div></div></div></div><div class="article-widget content-widget-hr"><h3>Latest</h3><ul><li><a href=/nii-yamagishilab/publication/shi-2022-can/>Can Knowledge of End-to-End Text-to-Speech Models Improve Neural MIDI-to-Audio Synthesis Systems?</a></li><li><a href=/nii-yamagishilab/publication/noe-2022-hiding/>Hiding speaker's sex in speech using zero-evidence speaker representation in an analysis/synthesis pipeline</a></li><li><a href=/nii-yamagishilab/publication/wang-2022-spoofed/>Spoofed training data for speech spoofing countermeasure can be efficiently created using neural vocoders</a></li><li><a href=/nii-yamagishilab/publication/wang-2022-investigating/>Investigating Active-Learning-Based Training Data Selection for Speech Spoofing Countermeasure</a></li><li><a href=/nii-yamagishilab/publication/zhang-2022-partial-spoof/>The PartialSpoof Database and Countermeasures for the Detection of Short Fake Speech Segments Embedded in an Utterance</a></li><li><a href=/nii-yamagishilab/publication/wang-2022/>A Practical Guide toÂ Logical Access Voice Presentation Attack Detection</a></li><li><a href=/nii-yamagishilab/publication/miao-22-interspeech/>Analyzing Language-Independent Speaker Anonymization Framework under Unseen Conditions</a></li><li><a href=/nii-yamagishilab/publication/9746688/>Attention Back-End for Automatic Speaker Verification with Multiple Enrollment Utterances</a></li><li><a href=/nii-yamagishilab/publication/tak-22-odyssey/>Automatic Speaker Verification Spoofing and Deepfake Detection Using Wav2vec 2.0 and Data Augmentation</a></li><li><a href=/nii-yamagishilab/publication/9746204/>Estimating the Confidence of Speech Spoofing Countermeasure</a></li><li><a href=/nii-yamagishilab/publication/wang-22-odyssey/>Investigating Self-Supervised Front Ends for Speech Spoofing Countermeasures</a></li><li><a href=/nii-yamagishilab/publication/zeng-2022-joint/>Joint Speaker Encoder and Neural Back-end Model for Fully End-to-End Automatic Speaker Verification with Multiple Enrollment Utterances</a></li><li><a href=/nii-yamagishilab/publication/miao-22-odyssey/>Language-Independent Speaker Anonymization Approach Using Self-Supervised Pre-Trained Models</a></li><li><a href=/nii-yamagishilab/publication/tomashenko-2022-voiceprivacy/>The VoicePrivacy 2020 Challenge: Results and findings</a></li><li><a href=/nii-yamagishilab/publication/kruengkrai-etal-2021-multi/>A Multi-Level Attention Model for Evidence-Based Fact Checking</a></li><li><a href=/nii-yamagishilab/publication/wang-21-fa-interspeech/>A Comparative Study on Recent Neural Spoofing Countermeasures for Synthetic Speech Detection</a></li><li><a href=/nii-yamagishilab/publication/zhang-21-ca-interspeech/>An Initial Investigation for Detecting Partially Spoofed Audio</a></li><li><a href=/nii-yamagishilab/publication/9358099/>ASVspoof 2019: Spoofing Countermeasures for the Detection of Synthesized, Converted and Replayed Speech</a></li><li><a href=/nii-yamagishilab/publication/yamagishi-21-asvspoof/>ASVspoof 2021: accelerating progress in spoofed and deepfake speech detection</a></li><li><a href=/nii-yamagishilab/publication/bonastre-21-spsc/>Benchmarking and challenges in security and privacy for voice biometrics</a></li><li><a href=/nii-yamagishilab/publication/9383611/>Denoising-and-Dereverberation Hierarchical Neural Vocoder for Robust Waveform Generation</a></li><li><a href=/nii-yamagishilab/publication/9414499/>End-to-End Text-to-Speech Using Latent Duration Based on VQ-VAE</a></li><li><a href=/nii-yamagishilab/publication/9414175/>How Similar or Different is Rakugo Speech Synthesizer to Professional Performers?</a></li><li><a href=/nii-yamagishilab/publication/zhang-21-asvspoof/>Multi-task Learning in Utterance-level and Segmental-level Spoof Detection</a></li><li><a href=/nii-yamagishilab/publication/cooper-21-b-ssw/>Text-to-Speech Synthesis Techniques for MIDI-to-Audio Synthesis</a></li></ul></div></div></section></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">Â© 2023 Yamagishi Lab. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> â the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/nii-yamagishilab/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
<script src=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js integrity crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/nii-yamagishilab/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script>
<script src=/nii-yamagishilab/en/js/wowchemy.min.e8ee06ba8371980ffde659871dd593b0.js></script>
<script src=/nii-yamagishilab/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js type=module></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/nii-yamagishilab/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>